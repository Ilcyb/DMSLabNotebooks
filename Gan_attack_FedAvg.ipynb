{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gan attack FedAvg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUyF1XfJWcxT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63b406e3-0ba5-4cb3-af94-496991f69356"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun  8 10:46:38 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoyrM3BcQ606",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad2947d-08dc-4efb-fce2-e50662ba7838"
      },
      "source": [
        "!git clone https://github.com/Ilcyb/Federated-Learning-PyTorch.git\n",
        "%cd Federated-Learning-PyTorch\n",
        "!pip3 install tensorboardX==1.4 tqdm==4.50.2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Federated-Learning-PyTorch'...\n",
            "remote: Enumerating objects: 437, done.\u001b[K\n",
            "remote: Total 437 (delta 0), reused 0 (delta 0), pack-reused 437\u001b[K\n",
            "Receiving objects: 100% (437/437), 242.93 KiB | 8.68 MiB/s, done.\n",
            "Resolving deltas: 100% (265/265), done.\n",
            "/content/Federated-Learning-PyTorch\n",
            "Collecting tensorboardX==1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/d2/e08fe62f3554fbba081e80f6b23128df53b2f74ed4dcde73ec4a84dc53fb/tensorboardX-1.4-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.6MB/s \n",
            "\u001b[?25hCollecting tqdm==4.50.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/cf/f91813073e4135c1183cadf968256764a6fe4e35c351d596d527c0540461/tqdm-4.50.2-py2.py3-none-any.whl (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.4) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.4) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.4) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.2.0->tensorboardX==1.4) (57.0.0)\n",
            "Installing collected packages: tensorboardX, tqdm\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed tensorboardX-1.4 tqdm-4.50.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQndl4uTRvNL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "235a477b-f446-4154-d295-c6c3e5583a73"
      },
      "source": [
        "# 切换至iid攻击分支\n",
        "!git checkout remotes/origin/ganattack_iid\n",
        "\n",
        "# 数据集\n",
        "%env dataset=mnist\n",
        "# 全局迭代次数\n",
        "%env epochs=100\n",
        "# 参与用户数\n",
        "%env num_users=100\n",
        "# 参与用户比例\n",
        "%env frac=0.1\n",
        "# 用户本地迭代次数\n",
        "%env local_ep=1\n",
        "# 想要窃取的数据类别\n",
        "%env wanted_label_index=1\n",
        "# 用户本地GAN一轮训练迭代次数\n",
        "%env local_gan_epoch=25\n",
        "# 用户本地GAN学习率\n",
        "%env local_gan_lr=0.002\n",
        "# 实验名\n",
        "%env experiment_name='test'\n",
        "\n",
        "# IID数据实验\n",
        "!python src/serverattack_main.py --mode=production --model=dcgan --dataset=$dataset --gpu=0 --epochs=$epochs --num_users=$num_users --frac=$frac --local_ep=$local_ep --wanted_label_index=$wanted_label_index --local_gan_epoch=$local_gan_epoch --local_gan_lr=$local_gan_lr --experiment_name=$experiment_name"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HEAD is now at 701b562 fix\n",
            "env: dataset=mnist\n",
            "env: epochs=100\n",
            "env: num_users=100\n",
            "env: frac=0.1\n",
            "env: local_ep=1\n",
            "env: wanted_label_index=1\n",
            "env: local_gan_epoch=25\n",
            "env: local_gan_lr=0.002\n",
            "env: experiment_name='test'\n",
            "\n",
            "Experimental details:\n",
            "    Model     : dcgan\n",
            "    Optimizer : sgd\n",
            "    Learning  : 0.01\n",
            "    Global Rounds   : 100\n",
            "\n",
            "    Federated parameters:\n",
            "    IID\n",
            "    Fraction of users  : 0.1\n",
            "    Local Batch size   : 10\n",
            "    Local Epochs       : 1\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "9913344it [00:00, 12674579.28it/s]               \n",
            "Extracting ./data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "29696it [00:00, 239667.60it/s]               \n",
            "Extracting ./data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "1649664it [00:49, 33489.79it/s]                 \n",
            "Extracting ./data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "5120it [00:00, 22724694.69it/s]\n",
            "Extracting ./data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw\n",
            "\n",
            "Processing...\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
            "Done!\n",
            "  0% 0/100 [00:00<?, ?it/s]\n",
            " | Global Training Round : 1 |\n",
            "\n",
            "/content/Federated-Learning-PyTorch/src/update.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(image), torch.tensor(label)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "  1% 1/100 [00:04<07:40,  4.65s/it]\n",
            " | Global Training Round : 2 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 2 global rounds:\n",
            "Training Loss : 2.1521490977456175\n",
            "Train Accuracy: 62.93% \n",
            "\n",
            "  2% 2/100 [00:09<07:28,  4.58s/it]\n",
            " | Global Training Round : 3 |\n",
            "\n",
            "  3% 3/100 [00:13<07:17,  4.51s/it]\n",
            " | Global Training Round : 4 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 4 global rounds:\n",
            "Training Loss : 1.8022661663591864\n",
            "Train Accuracy: 78.05% \n",
            "\n",
            "  4% 4/100 [00:17<07:06,  4.44s/it]\n",
            " | Global Training Round : 5 |\n",
            "\n",
            "  5% 5/100 [00:22<06:58,  4.41s/it]\n",
            " | Global Training Round : 6 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 6 global rounds:\n",
            "Training Loss : 1.488356596293549\n",
            "Train Accuracy: 84.13% \n",
            "\n",
            "  6% 6/100 [00:26<06:53,  4.40s/it]\n",
            " | Global Training Round : 7 |\n",
            "\n",
            "  7% 7/100 [00:30<06:45,  4.36s/it]\n",
            " | Global Training Round : 8 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 8 global rounds:\n",
            "Training Loss : 1.267402890790254\n",
            "Train Accuracy: 87.03% \n",
            "\n",
            "  8% 8/100 [00:34<06:38,  4.33s/it]\n",
            " | Global Training Round : 9 |\n",
            "\n",
            "  9% 9/100 [00:39<06:33,  4.33s/it]\n",
            " | Global Training Round : 10 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 10 global rounds:\n",
            "Training Loss : 1.1090173134626822\n",
            "Train Accuracy: 88.67% \n",
            "\n",
            " 10% 10/100 [00:43<06:28,  4.32s/it]\n",
            " | Global Training Round : 11 |\n",
            "\n",
            " 11% 11/100 [00:47<06:24,  4.32s/it]\n",
            " | Global Training Round : 12 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 12 global rounds:\n",
            "Training Loss : 0.992239357212869\n",
            "Train Accuracy: 90.30% \n",
            "\n",
            " 12% 12/100 [00:52<06:21,  4.34s/it]\n",
            " | Global Training Round : 13 |\n",
            "\n",
            " 13% 13/100 [00:56<06:17,  4.34s/it]\n",
            " | Global Training Round : 14 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 14 global rounds:\n",
            "Training Loss : 0.9005520950603699\n",
            "Train Accuracy: 91.23% \n",
            "\n",
            " 14% 14/100 [01:01<06:15,  4.37s/it]\n",
            " | Global Training Round : 15 |\n",
            "\n",
            " 15% 15/100 [01:05<06:14,  4.40s/it]\n",
            " | Global Training Round : 16 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 16 global rounds:\n",
            "Training Loss : 0.8263958939899263\n",
            "Train Accuracy: 92.07% \n",
            "\n",
            " 16% 16/100 [01:09<06:10,  4.41s/it]\n",
            " | Global Training Round : 17 |\n",
            "\n",
            " 17% 17/100 [01:14<06:04,  4.39s/it]\n",
            " | Global Training Round : 18 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 18 global rounds:\n",
            "Training Loss : 0.7646573196962924\n",
            "Train Accuracy: 92.63% \n",
            "\n",
            " 18% 18/100 [01:18<06:00,  4.39s/it]\n",
            " | Global Training Round : 19 |\n",
            "\n",
            " 19% 19/100 [01:22<05:53,  4.37s/it]\n",
            " | Global Training Round : 20 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 20 global rounds:\n",
            "Training Loss : 0.7129785649243664\n",
            "Train Accuracy: 93.02% \n",
            "\n",
            " 20% 20/100 [01:27<05:49,  4.36s/it]\n",
            " | Global Training Round : 21 |\n",
            "\n",
            " 21% 21/100 [01:31<05:43,  4.35s/it]\n",
            " | Global Training Round : 22 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 22 global rounds:\n",
            "Training Loss : 0.669281681266324\n",
            "Train Accuracy: 93.43% \n",
            "\n",
            " 22% 22/100 [01:36<05:39,  4.36s/it]\n",
            " | Global Training Round : 23 |\n",
            "\n",
            " 23% 23/100 [01:40<05:33,  4.33s/it]\n",
            " | Global Training Round : 24 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 24 global rounds:\n",
            "Training Loss : 0.6314232657505069\n",
            "Train Accuracy: 93.83% \n",
            "\n",
            " 24% 24/100 [01:44<05:28,  4.32s/it]\n",
            " | Global Training Round : 25 |\n",
            "\n",
            " 25% 25/100 [01:48<05:24,  4.33s/it]\n",
            " | Global Training Round : 26 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 26 global rounds:\n",
            "Training Loss : 0.5985511459751973\n",
            "Train Accuracy: 93.88% \n",
            "\n",
            " 26% 26/100 [01:53<05:20,  4.33s/it]\n",
            " | Global Training Round : 27 |\n",
            "\n",
            " 27% 27/100 [01:57<05:14,  4.31s/it]\n",
            " | Global Training Round : 28 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 28 global rounds:\n",
            "Training Loss : 0.5696075224603104\n",
            "Train Accuracy: 94.15% \n",
            "\n",
            " 28% 28/100 [02:01<05:11,  4.33s/it]\n",
            " | Global Training Round : 29 |\n",
            "\n",
            " 29% 29/100 [02:06<05:07,  4.33s/it]\n",
            " | Global Training Round : 30 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 30 global rounds:\n",
            "Training Loss : 0.5435774855649408\n",
            "Train Accuracy: 94.57% \n",
            "\n",
            " 30% 30/100 [02:10<05:02,  4.33s/it]\n",
            " | Global Training Round : 31 |\n",
            "\n",
            " 31% 31/100 [02:14<04:58,  4.32s/it]\n",
            " | Global Training Round : 32 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 32 global rounds:\n",
            "Training Loss : 0.5208735946536156\n",
            "Train Accuracy: 94.87% \n",
            "\n",
            " 32% 32/100 [02:19<04:54,  4.33s/it]\n",
            " | Global Training Round : 33 |\n",
            "\n",
            " 33% 33/100 [02:23<04:50,  4.33s/it]\n",
            " | Global Training Round : 34 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 34 global rounds:\n",
            "Training Loss : 0.500086888787679\n",
            "Train Accuracy: 95.05% \n",
            "\n",
            " 34% 34/100 [02:27<04:45,  4.33s/it]\n",
            " | Global Training Round : 35 |\n",
            "\n",
            " 35% 35/100 [02:32<04:41,  4.33s/it]\n",
            " | Global Training Round : 36 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 36 global rounds:\n",
            "Training Loss : 0.4815889943268201\n",
            "Train Accuracy: 95.25% \n",
            "\n",
            " 36% 36/100 [02:36<04:38,  4.35s/it]\n",
            " | Global Training Round : 37 |\n",
            "\n",
            " 37% 37/100 [02:40<04:33,  4.34s/it]\n",
            " | Global Training Round : 38 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 38 global rounds:\n",
            "Training Loss : 0.46449967320408997\n",
            "Train Accuracy: 95.40% \n",
            "\n",
            " 38% 38/100 [02:45<04:28,  4.33s/it]\n",
            " | Global Training Round : 39 |\n",
            "\n",
            " 39% 39/100 [02:49<04:23,  4.33s/it]\n",
            " | Global Training Round : 40 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 40 global rounds:\n",
            "Training Loss : 0.4489050463157763\n",
            "Train Accuracy: 95.62% \n",
            "\n",
            " 40% 40/100 [02:53<04:20,  4.33s/it]\n",
            " | Global Training Round : 41 |\n",
            "\n",
            " 41% 41/100 [02:58<04:15,  4.33s/it]\n",
            " | Global Training Round : 42 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 42 global rounds:\n",
            "Training Loss : 0.4342694781573271\n",
            "Train Accuracy: 95.93% \n",
            "\n",
            " 42% 42/100 [03:02<04:10,  4.32s/it]\n",
            " | Global Training Round : 43 |\n",
            "\n",
            " 43% 43/100 [03:06<04:07,  4.34s/it]\n",
            " | Global Training Round : 44 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 44 global rounds:\n",
            "Training Loss : 0.4207495582027177\n",
            "Train Accuracy: 96.00% \n",
            "\n",
            " 44% 44/100 [03:11<04:02,  4.33s/it]\n",
            " | Global Training Round : 45 |\n",
            "\n",
            " 45% 45/100 [03:15<03:57,  4.32s/it]\n",
            " | Global Training Round : 46 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 46 global rounds:\n",
            "Training Loss : 0.4085550924234364\n",
            "Train Accuracy: 96.22% \n",
            "\n",
            " 46% 46/100 [03:19<03:52,  4.31s/it]\n",
            " | Global Training Round : 47 |\n",
            "\n",
            " 47% 47/100 [03:24<03:47,  4.30s/it]\n",
            " | Global Training Round : 48 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 48 global rounds:\n",
            "Training Loss : 0.3967214596419783\n",
            "Train Accuracy: 96.27% \n",
            "\n",
            " 48% 48/100 [03:28<03:43,  4.31s/it]\n",
            " | Global Training Round : 49 |\n",
            "\n",
            " 49% 49/100 [03:32<03:39,  4.31s/it]\n",
            " | Global Training Round : 50 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 50 global rounds:\n",
            "Training Loss : 0.3858235102034135\n",
            "Train Accuracy: 96.43% \n",
            "\n",
            " 50% 50/100 [03:37<03:36,  4.33s/it]\n",
            " | Global Training Round : 51 |\n",
            "\n",
            " 51% 51/100 [03:41<03:31,  4.32s/it]\n",
            " | Global Training Round : 52 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 52 global rounds:\n",
            "Training Loss : 0.37552942460102845\n",
            "Train Accuracy: 96.57% \n",
            "\n",
            " 52% 52/100 [03:45<03:27,  4.31s/it]\n",
            " | Global Training Round : 53 |\n",
            "\n",
            " 53% 53/100 [03:50<03:22,  4.31s/it]\n",
            " | Global Training Round : 54 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 54 global rounds:\n",
            "Training Loss : 0.36613894270527825\n",
            "Train Accuracy: 96.63% \n",
            "\n",
            " 54% 54/100 [03:54<03:18,  4.31s/it]\n",
            " | Global Training Round : 55 |\n",
            "\n",
            " 55% 55/100 [03:58<03:14,  4.31s/it]\n",
            " | Global Training Round : 56 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 56 global rounds:\n",
            "Training Loss : 0.3573489614738459\n",
            "Train Accuracy: 96.63% \n",
            "\n",
            " 56% 56/100 [04:03<03:10,  4.33s/it]\n",
            " | Global Training Round : 57 |\n",
            "\n",
            " 57% 57/100 [04:07<03:06,  4.33s/it]\n",
            " | Global Training Round : 58 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 58 global rounds:\n",
            "Training Loss : 0.3487878428749679\n",
            "Train Accuracy: 96.77% \n",
            "\n",
            " 58% 58/100 [04:11<03:02,  4.34s/it]\n",
            " | Global Training Round : 59 |\n",
            "\n",
            " 59% 59/100 [04:16<02:57,  4.34s/it]\n",
            " | Global Training Round : 60 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 60 global rounds:\n",
            "Training Loss : 0.34083158836601396\n",
            "Train Accuracy: 96.82% \n",
            "\n",
            " 60% 60/100 [04:20<02:53,  4.34s/it]\n",
            " | Global Training Round : 61 |\n",
            "\n",
            " 61% 61/100 [04:24<02:49,  4.34s/it]\n",
            " | Global Training Round : 62 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 62 global rounds:\n",
            "Training Loss : 0.3332332720956186\n",
            "Train Accuracy: 96.98% \n",
            "\n",
            " 62% 62/100 [04:28<02:44,  4.32s/it]\n",
            " | Global Training Round : 63 |\n",
            "\n",
            " 63% 63/100 [04:33<02:39,  4.32s/it]\n",
            " | Global Training Round : 64 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 64 global rounds:\n",
            "Training Loss : 0.3260669300965901\n",
            "Train Accuracy: 97.00% \n",
            "\n",
            " 64% 64/100 [04:37<02:35,  4.31s/it]\n",
            " | Global Training Round : 65 |\n",
            "\n",
            " 65% 65/100 [04:41<02:31,  4.32s/it]\n",
            " | Global Training Round : 66 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 66 global rounds:\n",
            "Training Loss : 0.3190680270843843\n",
            "Train Accuracy: 96.98% \n",
            "\n",
            " 66% 66/100 [04:46<02:26,  4.32s/it]\n",
            " | Global Training Round : 67 |\n",
            "\n",
            " 67% 67/100 [04:50<02:21,  4.29s/it]\n",
            " | Global Training Round : 68 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 68 global rounds:\n",
            "Training Loss : 0.3127665300432258\n",
            "Train Accuracy: 96.93% \n",
            "\n",
            " 68% 68/100 [04:54<02:16,  4.28s/it]\n",
            " | Global Training Round : 69 |\n",
            "\n",
            " 69% 69/100 [04:58<02:12,  4.27s/it]\n",
            " | Global Training Round : 70 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 70 global rounds:\n",
            "Training Loss : 0.306547026131458\n",
            "Train Accuracy: 97.10% \n",
            "\n",
            " 70% 70/100 [05:03<02:08,  4.28s/it]\n",
            " | Global Training Round : 71 |\n",
            "\n",
            " 71% 71/100 [05:07<02:04,  4.29s/it]\n",
            " | Global Training Round : 72 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 72 global rounds:\n",
            "Training Loss : 0.30066865368244516\n",
            "Train Accuracy: 97.27% \n",
            "\n",
            " 72% 72/100 [05:11<02:00,  4.30s/it]\n",
            " | Global Training Round : 73 |\n",
            "\n",
            " 73% 73/100 [05:16<01:55,  4.29s/it]\n",
            " | Global Training Round : 74 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 74 global rounds:\n",
            "Training Loss : 0.29496654196757904\n",
            "Train Accuracy: 97.13% \n",
            "\n",
            " 74% 74/100 [05:20<01:51,  4.29s/it]\n",
            " | Global Training Round : 75 |\n",
            "\n",
            " 75% 75/100 [05:24<01:47,  4.28s/it]\n",
            " | Global Training Round : 76 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 76 global rounds:\n",
            "Training Loss : 0.2895945830137479\n",
            "Train Accuracy: 97.25% \n",
            "\n",
            " 76% 76/100 [05:29<01:42,  4.28s/it]\n",
            " | Global Training Round : 77 |\n",
            "\n",
            " 77% 77/100 [05:33<01:38,  4.29s/it]\n",
            " | Global Training Round : 78 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 78 global rounds:\n",
            "Training Loss : 0.28447958850706956\n",
            "Train Accuracy: 97.15% \n",
            "\n",
            " 78% 78/100 [05:37<01:34,  4.31s/it]\n",
            " | Global Training Round : 79 |\n",
            "\n",
            " 79% 79/100 [05:41<01:30,  4.31s/it]\n",
            " | Global Training Round : 80 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 80 global rounds:\n",
            "Training Loss : 0.2795466467431682\n",
            "Train Accuracy: 97.33% \n",
            "\n",
            " 80% 80/100 [05:46<01:25,  4.30s/it]\n",
            " | Global Training Round : 81 |\n",
            "\n",
            " 81% 81/100 [05:50<01:21,  4.29s/it]\n",
            " | Global Training Round : 82 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 82 global rounds:\n",
            "Training Loss : 0.27484867321699114\n",
            "Train Accuracy: 97.32% \n",
            "\n",
            " 82% 82/100 [05:54<01:17,  4.29s/it]\n",
            " | Global Training Round : 83 |\n",
            "\n",
            " 83% 83/100 [05:59<01:12,  4.28s/it]\n",
            " | Global Training Round : 84 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 84 global rounds:\n",
            "Training Loss : 0.27019882467562667\n",
            "Train Accuracy: 97.42% \n",
            "\n",
            " 84% 84/100 [06:03<01:08,  4.28s/it]\n",
            " | Global Training Round : 85 |\n",
            "\n",
            " 85% 85/100 [06:07<01:04,  4.29s/it]\n",
            " | Global Training Round : 86 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 86 global rounds:\n",
            "Training Loss : 0.26586376440919673\n",
            "Train Accuracy: 97.50% \n",
            "\n",
            " 86% 86/100 [06:12<01:00,  4.31s/it]\n",
            " | Global Training Round : 87 |\n",
            "\n",
            " 87% 87/100 [06:16<00:56,  4.31s/it]\n",
            " | Global Training Round : 88 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 88 global rounds:\n",
            "Training Loss : 0.26179866910819277\n",
            "Train Accuracy: 97.57% \n",
            "\n",
            " 88% 88/100 [06:20<00:51,  4.30s/it]\n",
            " | Global Training Round : 89 |\n",
            "\n",
            " 89% 89/100 [06:24<00:47,  4.31s/it]\n",
            " | Global Training Round : 90 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 90 global rounds:\n",
            "Training Loss : 0.25770520678478837\n",
            "Train Accuracy: 97.50% \n",
            "\n",
            " 90% 90/100 [06:29<00:43,  4.31s/it]\n",
            " | Global Training Round : 91 |\n",
            "\n",
            " 91% 91/100 [06:33<00:38,  4.30s/it]\n",
            " | Global Training Round : 92 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 92 global rounds:\n",
            "Training Loss : 0.25380205578812426\n",
            "Train Accuracy: 97.62% \n",
            "\n",
            " 92% 92/100 [06:37<00:34,  4.33s/it]\n",
            " | Global Training Round : 93 |\n",
            "\n",
            " 93% 93/100 [06:42<00:30,  4.32s/it]\n",
            " | Global Training Round : 94 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 94 global rounds:\n",
            "Training Loss : 0.2500556499843071\n",
            "Train Accuracy: 97.57% \n",
            "\n",
            " 94% 94/100 [06:46<00:25,  4.33s/it]\n",
            " | Global Training Round : 95 |\n",
            "\n",
            " 95% 95/100 [06:50<00:21,  4.34s/it]\n",
            " | Global Training Round : 96 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 96 global rounds:\n",
            "Training Loss : 0.24656059662015903\n",
            "Train Accuracy: 97.63% \n",
            "\n",
            " 96% 96/100 [06:55<00:17,  4.34s/it]\n",
            " | Global Training Round : 97 |\n",
            "\n",
            " 97% 97/100 [06:59<00:13,  4.34s/it]\n",
            " | Global Training Round : 98 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 98 global rounds:\n",
            "Training Loss : 0.24301504085419673\n",
            "Train Accuracy: 97.67% \n",
            "\n",
            " 98% 98/100 [07:03<00:08,  4.33s/it]\n",
            " | Global Training Round : 99 |\n",
            "\n",
            " 99% 99/100 [07:08<00:04,  4.32s/it]\n",
            " | Global Training Round : 100 |\n",
            "\n",
            " \n",
            "Avg Training Stats after 100 global rounds:\n",
            "Training Loss : 0.239760149797609\n",
            "Train Accuracy: 97.75% \n",
            "\n",
            "100% 100/100 [07:12<00:00,  4.32s/it]\n",
            "fake images shape:torch.Size([1, 28, 28])\n",
            " \n",
            " Results after 100 global rounds of training:\n",
            "|---- Avg Train Accuracy: 97.75%\n",
            "|---- Test Accuracy: 98.00%\n",
            "\n",
            " Total Run Time: 498.9156\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}